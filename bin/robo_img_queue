#!/usr/bin/env python3
#######################################################################################################################
# IMG PULL QUEUE SCRIPT
# Runs a pull queue for new images taken by the Robo88 Observer system.
# #
# Author: Kyle Hart
# Date 20 April 2024
#######################################################################################################################

from confluent_kafka import Consumer
import logging
import traceback
import datetime
import subprocess
import signal
import socket
import json
import sys
import os

OBSERVATION_MACHINE = "10.88.10.21"


def sig_handler(_signo, _stack_frame):
    """
    SIGNAL HANDLER, allows gracefull exit when run as daemon
    """
    sys.exit(0)


# Bring up observer, must already be started
date = datetime.datetime.utcnow()
obs_night = f"{date.year}{date.month:02d}{date.day:02d}"

# Get data dir
data_dir = sys.argv[1]

# Create Unique pull group for host
group = socket.gethostname() + "_group"
# Create consumer
kafka_conf = {'bootstrap.servers': f"{OBSERVATION_MACHINE}:9092",
              'group.id': group,
              'enable.auto.commit': False,
              'enable.auto.offset.store': True,
              'enable.partition.eof': False,
              'max.poll.interval.ms': 3600000,
              'session.timeout.ms': 1200000,
              'heartbeat.interval.ms': 3000,
              'auto.offset.reset': 'smallest'}
consumer = Consumer(kafka_conf)
consumer.subscribe(["robo_img_queue"])

# Create logger
logger = logging.getLogger("robo_img_queue")
logger.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(formatter)
logger.addHandler(handler)

# Log to file
logfile = os.path.join(data_dir, "robo_img_queue.log")
handler = logging.FileHandler(logfile)
handler.setFormatter(formatter)
logger.addHandler(handler)

# Signal for main process
signal.signal(signal.SIGINT, sig_handler)
signal.signal(signal.SIGTERM, sig_handler)

# Consumer loop
try:
    logger.info({'status': "starting queue"})
    while True:
        # Get next coadd in Kafka queue
        msg = consumer.poll(timeout=1.0)

        # No message, try again
        if msg is None:
            continue

        # Raise error
        elif msg.error():
            logger.error({'pull_error': msg.error().str()})

        # Process message (pull image)
        else:
            # Get image meta
            img = json.loads(msg.value().decode('utf-8'))
            # Remove root dir (/obs/data/) and pull
            dest = os.path.join(data_dir, img["img_path"][10:])
            # Create if necessary
            if not os.path.exists(dest):
                os.makedirs(dest, exist_ok=True)
            # Pull
            cmd = "scp -C " + "obs_admin@" + OBSERVATION_MACHINE + ":" + img['img_path'] + " " + dest
            result = subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            if result.returncode == 0:
                logger.info(img)
            else:
                logger.error({'pull_error': f"Secure Copy (scp) Unsuccessful: {cmd}"})
            # Commit
            consumer.commit(asynchronous=False)
except Exception as e:
    logger.error(traceback.format_exception(e))

finally:
    consumer.close()
